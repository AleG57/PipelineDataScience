{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57f1aab-65ad-417c-a2b3-0183086888aa",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis (QDA)\n",
    "---\n",
    "## 1.1 Formulation mathématique\n",
    "\n",
    "La QDA est une méthode statistique de classification supervisée. Pour chaque classes $k$ associée à une valeur de sortie $y \\in \\mathcal{Y} = \\{ k |  i \\in \\mathbb{N}^*\\}$, on considère que ces classes suivent une répartition gaussienne et que chaque classe a sa propre matrice de covariance. i.e.\n",
    "\n",
    "$$\n",
    "\\boxed{X | Y = k \\sim \\mathcal{N}(\\mu_k, \\Sigma_k)}\n",
    "$$\n",
    "\n",
    "Avec : \n",
    "\n",
    "$$\n",
    "\\quad \\mu_k \\in \\mathbb{R}^n, \\Sigma_k \\in \\mathcal{M}_{n}(\\mathbb{R}), \\forall k, n \\in \\mathbb{N}^* \\times \\mathbb{N}^*\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Retour sur la matrice de covariance et de corrélation\n",
    "\n",
    "* **Matrice de corrélation**. Pour un ensemble de variables $(X_n)_{n \\in \\mathbb{N}}$ Une matrice de corrélation est une matrice symétrique $\\Sigma$ tel que :\n",
    "\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "r_{1,1} & \\dots & r_{1,n} \\\\\n",
    "\\vdots & r_{i,j} & \\vdots \\\\\n",
    "r_{n,1} & \\dots & r_{n,n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "avec les $(r_{i,j})_{i, j \\in \\mathbb{N} \\times \\mathbb{N}}$ les coefficients de corrélation tels que :\n",
    "\n",
    "$$\n",
    "r_{i,j} = \\text{Corr}(X_i,X_j) = \\frac{\\text{Cov}(X_i, X_j)}{\\sigma_{X_{i}} \\sigma_{X_{j}}} \\quad \\forall i, j \\in \\mathbb{N}^* \\times \\mathbb{N}^*\n",
    "$$\n",
    "\n",
    "avec $\\text{Cov}(X_i, X_j) = \\mathbb{E}[(X_i - \\mathbb{E}(X_i))(X_j - \\mathbb{E}(X_j))]$. Pour des échantillons $\\{(x_i^n,x_j^n) | n \\in \\mathbb{N}\\}$, un estimateur du coefficient de corrélation de $r_{i,j}$ noté $\\hat{r_{i,j}}$ est donné par les relations suivantes\n",
    "\n",
    "$$\n",
    "\\hat{r_{i,j}} = \\frac{\\hat{\\sigma_{X_i,X_j}}}{\\hat{\\sigma_{X_{i}}} \\hat{\\sigma_{X_{j}}}}\n",
    "$$\n",
    "\n",
    "Avec : \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{X,Y} = \\frac{1}{N}\\sum_{k=1}^{N}(x_i - \\bar{x})(y_i - \\bar{y}), \\quad \\hat{\\sigma}_{S} = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}(s_i - \\bar{s})²}, \\quad \\bar{s} = \\frac{1}{N}\\sum_{k=1}^{N}s_i, \\quad S = X \\quad \\text{ou} \\quad S = Y\n",
    "$$\n",
    "\n",
    "* **Matrice de covariance**. Pour un ensemble de variables $(X_n)_{n \\in \\mathbb{N}}$ Une matrice de covariance est une matrice symétrique $\\Sigma$ tel que :\n",
    "\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{1,1} & \\dots & \\sigma_{1,n} \\\\\n",
    "\\vdots & \\sigma_{i,j} & \\vdots \\\\\n",
    "\\sigma_{n,1} & \\dots & \\sigma_{n,n} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "avec les $(\\sigma_{i,j})_{i, j \\in \\mathbb{N} \\times \\mathbb{N}}$ la covariance entre les variables $X_i$ et $X_j$ tels que :\n",
    "\n",
    "$$\n",
    "\\sigma_{i,j} = \\text{Cov}(X_i, X_j) = \\mathbb{E}[(X_i - \\mathbb{E}(X_i))(X_j - \\mathbb{E}(X_j))], \\quad \\forall i, j \\in \\mathbb{N}^* \\times \\mathbb{N}^*\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/DiscriminantAnalysis/qda_iris.png\" alt=\"a\" width=\"750\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46408fda-daf8-4bfa-8479-ee047d8a198c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
