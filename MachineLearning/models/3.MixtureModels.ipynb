{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7cccb7-a161-4de4-bcd6-c24b0aef26fb",
   "metadata": {},
   "source": [
    "# Modèles de mixture (MM) et Algorithme EM (Expectation - Maximization)\n",
    "---\n",
    "\n",
    "## 1. Formulation mathématique\n",
    "### 1.1 L'algorithme EM\n",
    "\n",
    "On se donne en ensemble $(X_i)_{i \\in \\mathbb{N}^*} \\in X$ variables observées et $(Z_i)_{i \\in \\mathbb{N}^*} \\in Z$ variables cachées. On cherche à optimiser un ensemble de paramètres $\\theta$ à partir du *likelyhood* (on cherche le maximum de vraisemblance). En considérant des données observées $(x_i)_{i \\in \\mathbb{N}^*}$ i.i.d., le *likelyhood* s'exprime sous la forme :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta) &= p(X \\mid \\theta)                   \\\\ \n",
    "                    &= p(x_1, \\dots, x_N \\mid \\theta)     \\\\\n",
    "                    &= \\prod_{i=1}^N p(x_n \\mid \\theta)     \\\\\n",
    "\\mathcal{L}(\\theta) &= \\prod_{i=1}^N p(X = x_n \\mid \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Ici, on y ajoute les variables cachées $Z_i$ pas nécéssairement i.i.d., i.e.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta) &= p(X \\mid \\theta)                                    \\\\\n",
    "                    &= \\sum_{Z} p(X,Z \\mid \\theta)                          \\\\\n",
    "                    &= \\sum_{i=1}^N p(x_1, \\dots, x_N, z_i \\mid \\theta)   \\\\\n",
    "                    &= \\prod_{i=1}^N \\sum_{i=1}^N p(x_n, z_i \\mid \\theta) \\\\\n",
    "\\mathcal{L}(\\theta) &= \\prod_{i=1}^N \\sum_{i=1}^N p(X = x_n, Z = z_i \\mid \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Pour simplifier le calcul du produit, on passe au $\\log$, ce qui donne :\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta) = \\log p(X \\mid \\theta) = \\log \\prod_{i=1}^N \\sum_{i=1}^N p(X = x_n, Z = z_i \\mid \\theta) = \\sum_{n=1}^N \\log( \\sum_{i=1}^N p(X = x_n, Z = z_i \\mid \\theta) )\n",
    "$$\n",
    "\n",
    "La forme \"$\\log \\sum$\" étant difficile à optimiser, on introduit donc une densité de probabilité (d.d.p. ou p.d.f) $q(Z)$ qui approxime le *posterior* $p(Z \\mid X, \\theta)$ tel que :\n",
    "\n",
    "$$\n",
    "p(Z \\mid X, \\theta) \\approx q(Z)\n",
    "$$\n",
    "\n",
    "Puis on introduit l'ELBO (evidence lower bound) définit par la moyenne de la log-probabilité jointe $p(X, Z \\mid \\theta)$ retranchée à l'entropie de $q$. L'ELBO est une borne inférieure de $p(X \\mid \\theta)$ qui permet sous certaines conditions de calculer le *likelyhood*. Autrement dit :\n",
    "\n",
    "$$\n",
    "\\text(ELBO)(q,\\theta) =\n",
    "\\underbrace{\n",
    "\\mathbb{E}_{q(Z)}[ \\log p(X,Z \\mid \\theta) ]\n",
    "}_{\\text{moyenne de la log-proba jointe}}\n",
    "-(\n",
    "\\underbrace{\n",
    "\\mathbb{E}_{q(Z)}[ \\log q(Z) ]\n",
    "}_{\\text{Entropie de } q(Z)}\n",
    ") \n",
    "\\quad \\text{qui induit} \\quad\n",
    "\\log p(X| \\theta) = \\log \\mathcal{L}(q,Z) + KL(q(Z) || p(Z \\mid X, \\theta)) \\geq \\mathcal{L}(q,Z)\n",
    "$$\n",
    "\n",
    "Avec $KL(\\bullet || \\bullet)$ la divergence de Kullback-Liebler, une mesure de la distance entre deux p.d.f. SOient $p$ et $q$ deux p;d.f. La divergence de Kullback-Liebler s'exprime sous la forme :\n",
    "\n",
    "$$\n",
    "KL(q||p) = \\sum_{z = 1}^Z q(z_i) \\log \\frac{q(z_i)}{p(z_i)}\n",
    "$$\n",
    "\n",
    "En particulier si $q(Z) = p(Z | X, \\theta)$, KL = 0 et par conséquent $p(X| \\theta) = \\mathcal{L}(q,Z)$. L'algorithme EM cherche donc à toruver un $q(Z)$ qui approxime $p(Z | X, \\theta)$ de telle sorte à maximiser une approximation du *likelyhood*.\n",
    "\n",
    "### 1.2 Etapes de l'algorithme\n",
    "\n",
    "* Etape E (Expectation)\n",
    "\n",
    "On met à jour la distribution sur les variables cachées :\n",
    "\n",
    "$$\n",
    "q(Z) \\leftarrow p(Z \\mid X, \\theta^{(t)})\n",
    "$$\n",
    "\n",
    "* Etape M (Maximization)\n",
    "\n",
    "On met à jour les paramètres en maximisant l’espérance de la log-vraisemblance (moyenne du *Likelyhood*) :\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)} \\leftarrow \\arg\\max_{\\theta} \\; \\mathbb{E}_{q(Z)} \\left[ \\log p(X,Z \\mid \\theta) \\right]\n",
    "$$\n",
    "\n",
    "### 1.3 Les modèles de mixture\n",
    "\n",
    "Un modèle de mixture est une combinaison linéaire de distributions usuelles.\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "---\n",
    "#### Retour sur les densités de probabilité usuelles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Un exemple en Python\n",
    "---\n",
    "#### 2.1 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876df68d-f90a-4cac-bde4-d8e3e42dbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3e5e5-507b-4735-9c4c-88df3db841c2",
   "metadata": {},
   "source": [
    "Dans cet exemple, on génère un mélange de deux gaussiennes. On cherche à savoir laquelle des deux gaussiennes a généré le point $x_n$ : c'est la variable cachée. On note donc $Z \\in \\{1;2\\}$ le numéro de la gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9b29c2-2732-4b62-8032-c4213d8e9c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 01 | mu=[ 3.69863696 -1.00488823] | sigma=[1.05003648 1.75234107] | pi=[0.32206412 0.67793588] | logL=-698.165\n",
      "Iter 02 | mu=[ 3.54090695 -1.08363663] | sigma=[1.14290341 1.74116683] | pi=[0.34459294 0.65540706] | logL=-693.851\n",
      "Iter 03 | mu=[ 3.44340743 -1.19161637] | sigma=[1.18439797 1.66794625] | pi=[0.36711027 0.63288973] | logL=-690.721\n",
      "Iter 04 | mu=[ 3.36721355 -1.30441853] | sigma=[1.21086476 1.57313656] | pi=[0.38837968 0.61162032] | logL=-687.529\n",
      "Iter 05 | mu=[ 3.2981072  -1.41304813] | sigma=[1.2341565 1.4728592] | pi=[0.40817941 0.59182059] | logL=-684.326\n",
      "Iter 06 | mu=[ 3.2326917  -1.51155464] | sigma=[1.258832   1.37683135] | pi=[0.42609573 0.57390427] | logL=-681.372\n",
      "Iter 07 | mu=[ 3.17144746 -1.59567037] | sigma=[1.28599208 1.29245368] | pi=[0.44169641 0.55830359] | logL=-678.936\n",
      "Iter 08 | mu=[ 3.11589961 -1.66351686] | sigma=[1.31476169 1.224205  ] | pi=[0.45475537 0.54524463] | logL=-677.153\n",
      "Iter 09 | mu=[ 3.06732117 -1.71588196] | sigma=[1.34333442 1.17261591] | pi=[0.46534307 0.53465693] | logL=-675.970\n",
      "Iter 10 | mu=[ 3.02618412 -1.75531514] | sigma=[1.36994172 1.13517177] | pi=[0.47375592 0.52624408] | logL=-675.232\n",
      "Iter 11 | mu=[ 2.99216209 -1.7848133 ] | sigma=[1.39346734 1.10834212] | pi=[0.48037965 0.51962035] | logL=-674.782\n",
      "Iter 12 | mu=[ 2.96443367 -1.80699286] | sigma=[1.41352975 1.08899437] | pi=[0.48558671 0.51441329] | logL=-674.509\n",
      "Iter 13 | mu=[ 2.94200721 -1.82384749] | sigma=[1.43025339 1.07481877] | pi=[0.48969096 0.51030904] | logL=-674.343\n",
      "Iter 14 | mu=[ 2.92392568 -1.8368087 ] | sigma=[1.44401019 1.06424033] | pi=[0.49294016 0.50705984] | logL=-674.240\n",
      "Iter 15 | mu=[ 2.90935506 -1.84688644] | sigma=[1.45524579 1.05620975] | pi=[0.49552465 0.50447535] | logL=-674.175\n",
      "Iter 16 | mu=[ 2.89760417 -1.8547965 ] | sigma=[1.46439027 1.05002386] | pi=[0.49758956 0.50241044] | logL=-674.134\n",
      "Iter 17 | mu=[ 2.88811414 -1.86105354] | sigma=[1.47182233 1.04520205] | pi=[0.4992458 0.5007542] | logL=-674.108\n",
      "Iter 18 | mu=[ 2.88043798 -1.86603423] | sigma=[1.47786092 1.04140778] | pi=[0.50057866 0.49942134] | logL=-674.091\n",
      "Iter 19 | mu=[ 2.87421953 -1.87001902] | sigma=[1.48276867 1.03839956] | pi=[0.50165426 0.49834574] | logL=-674.080\n",
      "Iter 20 | mu=[ 2.86917495 -1.87322001] | sigma=[1.48675948 1.03600032] | pi=[0.50252425 0.49747575] | logL=-674.073\n",
      "Iter 21 | mu=[ 2.86507766 -1.87579978] | sigma=[1.49000668 1.03407769] | pi=[0.50322926 0.49677074] | logL=-674.069\n",
      "Iter 22 | mu=[ 2.86174629 -1.87788436] | sigma=[1.49265045 1.03253117] | pi=[0.50380145 0.49619855] | logL=-674.066\n",
      "Iter 23 | mu=[ 2.85903526 -1.87957237] | sigma=[1.49480416 1.03128341] | pi=[0.50426645 0.49573355] | logL=-674.064\n",
      "Iter 24 | mu=[ 2.85682743 -1.88094161] | sigma=[1.49655954 1.03027425] | pi=[0.50464471 0.49535529] | logL=-674.062\n",
      "Iter 25 | mu=[ 2.85502828 -1.88205382] | sigma=[1.4979909  1.02945647] | pi=[0.50495267 0.49504733] | logL=-674.061\n",
      "Iter 26 | mu=[ 2.85356141 -1.88295826] | sigma=[1.49915848 1.02879272] | pi=[0.50520358 0.49479642] | logL=-674.061\n",
      "Iter 27 | mu=[ 2.85236496 -1.88369443] | sigma=[1.5001112  1.02825331] | pi=[0.50540812 0.49459188] | logL=-674.060\n",
      "Iter 28 | mu=[ 2.85138873 -1.88429407] | sigma=[1.50088881 1.02781448] | pi=[0.50557494 0.49442506] | logL=-674.060\n",
      "Iter 29 | mu=[ 2.85059196 -1.8847828 ] | sigma=[1.50152363 1.02745719] | pi=[0.50571103 0.49428897] | logL=-674.060\n",
      "Iter 30 | mu=[ 2.84994151 -1.88518133] | sigma=[1.50204198 1.02716608] | pi=[0.5058221 0.4941779] | logL=-674.060\n",
      "Iter 31 | mu=[ 2.8494104  -1.88550644] | sigma=[1.50246529 1.02692876] | pi=[0.50591277 0.49408723] | logL=-674.060\n",
      "Iter 32 | mu=[ 2.84897667 -1.88577174] | sigma=[1.50281104 1.0267352 ] | pi=[0.5059868 0.4940132] | logL=-674.060\n",
      "Iter 33 | mu=[ 2.84862242 -1.8859883 ] | sigma=[1.50309345 1.02657728] | pi=[0.50604725 0.49395275] | logL=-674.060\n",
      "Iter 34 | mu=[ 2.84833306 -1.8861651 ] | sigma=[1.50332416 1.0264484 ] | pi=[0.50609663 0.49390337] | logL=-674.060\n",
      "Iter 35 | mu=[ 2.84809668 -1.88630947] | sigma=[1.50351265 1.02634319] | pi=[0.50613696 0.49386304] | logL=-674.060\n",
      "Iter 36 | mu=[ 2.84790356 -1.88642738] | sigma=[1.50366664 1.02625728] | pi=[0.5061699 0.4938301] | logL=-674.060\n",
      "Iter 37 | mu=[ 2.84774578 -1.88652369] | sigma=[1.50379246 1.02618713] | pi=[0.50619682 0.49380318] | logL=-674.060\n",
      "Iter 38 | mu=[ 2.84761686 -1.88660236] | sigma=[1.50389527 1.02612983] | pi=[0.50621881 0.49378119] | logL=-674.060\n",
      "Iter 39 | mu=[ 2.84751153 -1.88666663] | sigma=[1.50397927 1.02608303] | pi=[0.50623678 0.49376322] | logL=-674.060\n",
      "Iter 40 | mu=[ 2.84742545 -1.88671914] | sigma=[1.50404792 1.0260448 ] | pi=[0.50625146 0.49374854] | logL=-674.060\n",
      "Iter 41 | mu=[ 2.84735512 -1.88676204] | sigma=[1.50410401 1.02601356] | pi=[0.50626345 0.49373655] | logL=-674.060\n",
      "Iter 42 | mu=[ 2.84729765 -1.88679709] | sigma=[1.50414984 1.02598804] | pi=[0.50627325 0.49372675] | logL=-674.060\n",
      "Iter 43 | mu=[ 2.84725069 -1.88682574] | sigma=[1.5041873  1.02596719] | pi=[0.50628126 0.49371874] | logL=-674.060\n",
      "Iter 44 | mu=[ 2.84721231 -1.88684914] | sigma=[1.50421791 1.02595016] | pi=[0.50628781 0.49371219] | logL=-674.060\n",
      "Iter 45 | mu=[ 2.84718095 -1.88686827] | sigma=[1.50424292 1.02593624] | pi=[0.50629316 0.49370684] | logL=-674.060\n",
      "Iter 46 | mu=[ 2.84715532 -1.88688389] | sigma=[1.50426336 1.02592486] | pi=[0.50629753 0.49370247] | logL=-674.060\n",
      "Iter 47 | mu=[ 2.84713438 -1.88689666] | sigma=[1.50428007 1.02591557] | pi=[0.5063011 0.4936989] | logL=-674.060\n",
      "Iter 48 | mu=[ 2.84711726 -1.8869071 ] | sigma=[1.50429372 1.02590797] | pi=[0.50630402 0.49369598] | logL=-674.060\n",
      "Iter 49 | mu=[ 2.84710328 -1.88691563] | sigma=[1.50430487 1.02590176] | pi=[0.5063064 0.4936936] | logL=-674.060\n",
      "Iter 50 | mu=[ 2.84709185 -1.8869226 ] | sigma=[1.50431399 1.02589669] | pi=[0.50630835 0.49369165] | logL=-674.060\n",
      "Iter 51 | mu=[ 2.84708251 -1.88692829] | sigma=[1.50432144 1.02589255] | pi=[0.50630995 0.49369005] | logL=-674.060\n",
      "Iter 52 | mu=[ 2.84707487 -1.88693294] | sigma=[1.50432753 1.02588916] | pi=[0.50631125 0.49368875] | logL=-674.060\n",
      "Iter 53 | mu=[ 2.84706863 -1.88693675] | sigma=[1.5043325  1.02588639] | pi=[0.50631231 0.49368769] | logL=-674.060\n",
      "Iter 54 | mu=[ 2.84706354 -1.88693986] | sigma=[1.50433657 1.02588413] | pi=[0.50631318 0.49368682] | logL=-674.060\n",
      "Iter 55 | mu=[ 2.84705937 -1.8869424 ] | sigma=[1.50433989 1.02588228] | pi=[0.50631389 0.49368611] | logL=-674.060\n",
      "Iter 56 | mu=[ 2.84705596 -1.88694447] | sigma=[1.50434261 1.02588077] | pi=[0.50631447 0.49368553] | logL=-674.060\n",
      "Iter 57 | mu=[ 2.84705318 -1.88694617] | sigma=[1.50434483 1.02587953] | pi=[0.50631495 0.49368505] | logL=-674.060\n",
      "Iter 58 | mu=[ 2.84705091 -1.88694755] | sigma=[1.50434664 1.02587853] | pi=[0.50631533 0.49368467] | logL=-674.060\n",
      "Iter 59 | mu=[ 2.84704905 -1.88694869] | sigma=[1.50434812 1.0258777 ] | pi=[0.50631565 0.49368435] | logL=-674.060\n",
      "Iter 60 | mu=[ 2.84704753 -1.88694961] | sigma=[1.50434934 1.02587703] | pi=[0.50631591 0.49368409] | logL=-674.060\n",
      "Iter 61 | mu=[ 2.84704629 -1.88695037] | sigma=[1.50435033 1.02587648] | pi=[0.50631612 0.49368388] | logL=-674.060\n",
      "Iter 62 | mu=[ 2.84704528 -1.88695099] | sigma=[1.50435113 1.02587603] | pi=[0.50631629 0.49368371] | logL=-674.060\n",
      "Iter 63 | mu=[ 2.84704445 -1.88695149] | sigma=[1.5043518  1.02587566] | pi=[0.50631644 0.49368356] | logL=-674.060\n",
      "Iter 64 | mu=[ 2.84704377 -1.88695191] | sigma=[1.50435234 1.02587536] | pi=[0.50631655 0.49368345] | logL=-674.060\n",
      "Iter 65 | mu=[ 2.84704322 -1.88695224] | sigma=[1.50435278 1.02587511] | pi=[0.50631665 0.49368335] | logL=-674.060\n",
      "Iter 66 | mu=[ 2.84704276 -1.88695252] | sigma=[1.50435314 1.02587491] | pi=[0.50631672 0.49368328] | logL=-674.060\n",
      "Iter 67 | mu=[ 2.84704239 -1.88695275] | sigma=[1.50435343 1.02587475] | pi=[0.50631679 0.49368321] | logL=-674.060\n",
      "Iter 68 | mu=[ 2.84704209 -1.88695293] | sigma=[1.50435367 1.02587461] | pi=[0.50631684 0.49368316] | logL=-674.060\n",
      "Iter 69 | mu=[ 2.84704185 -1.88695308] | sigma=[1.50435387 1.0258745 ] | pi=[0.50631688 0.49368312] | logL=-674.060\n",
      "Iter 70 | mu=[ 2.84704164 -1.8869532 ] | sigma=[1.50435403 1.02587441] | pi=[0.50631691 0.49368309] | logL=-674.060\n",
      "Iter 71 | mu=[ 2.84704148 -1.8869533 ] | sigma=[1.50435416 1.02587434] | pi=[0.50631694 0.49368306] | logL=-674.060\n",
      "Iter 72 | mu=[ 2.84704134 -1.88695339] | sigma=[1.50435427 1.02587428] | pi=[0.50631696 0.49368304] | logL=-674.060\n",
      "Iter 73 | mu=[ 2.84704123 -1.88695345] | sigma=[1.50435436 1.02587423] | pi=[0.50631698 0.49368302] | logL=-674.060\n",
      "Iter 74 | mu=[ 2.84704114 -1.88695351] | sigma=[1.50435443 1.02587419] | pi=[0.506317 0.493683] | logL=-674.060\n",
      "Iter 75 | mu=[ 2.84704107 -1.88695355] | sigma=[1.50435449 1.02587416] | pi=[0.50631701 0.49368299] | logL=-674.060\n",
      "Iter 76 | mu=[ 2.84704101 -1.88695359] | sigma=[1.50435454 1.02587413] | pi=[0.50631702 0.49368298] | logL=-674.060\n",
      "Iter 77 | mu=[ 2.84704096 -1.88695362] | sigma=[1.50435458 1.02587411] | pi=[0.50631703 0.49368297] | logL=-674.060\n",
      "Iter 78 | mu=[ 2.84704092 -1.88695364] | sigma=[1.50435461 1.02587409] | pi=[0.50631704 0.49368296] | logL=-674.060\n",
      "Iter 79 | mu=[ 2.84704089 -1.88695366] | sigma=[1.50435463 1.02587408] | pi=[0.50631704 0.49368296] | logL=-674.060\n",
      "Iter 80 | mu=[ 2.84704086 -1.88695368] | sigma=[1.50435466 1.02587407] | pi=[0.50631705 0.49368295] | logL=-674.060\n",
      "Iter 81 | mu=[ 2.84704084 -1.88695369] | sigma=[1.50435467 1.02587406] | pi=[0.50631705 0.49368295] | logL=-674.060\n",
      "Iter 82 | mu=[ 2.84704082 -1.8869537 ] | sigma=[1.50435469 1.02587405] | pi=[0.50631705 0.49368295] | logL=-674.060\n",
      "Iter 83 | mu=[ 2.84704081 -1.88695371] | sigma=[1.5043547  1.02587404] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 84 | mu=[ 2.84704079 -1.88695372] | sigma=[1.50435471 1.02587404] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 85 | mu=[ 2.84704079 -1.88695373] | sigma=[1.50435472 1.02587403] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 86 | mu=[ 2.84704078 -1.88695373] | sigma=[1.50435472 1.02587403] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 87 | mu=[ 2.84704077 -1.88695374] | sigma=[1.50435473 1.02587403] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 88 | mu=[ 2.84704077 -1.88695374] | sigma=[1.50435473 1.02587402] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 89 | mu=[ 2.84704076 -1.88695374] | sigma=[1.50435474 1.02587402] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 90 | mu=[ 2.84704076 -1.88695374] | sigma=[1.50435474 1.02587402] | pi=[0.50631706 0.49368294] | logL=-674.060\n",
      "Iter 91 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435474 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 92 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435474 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 93 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435474 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 94 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 95 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 96 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 97 | mu=[ 2.84704075 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 98 | mu=[ 2.84704074 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 99 | mu=[ 2.84704074 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n",
      "Iter 100 | mu=[ 2.84704074 -1.88695375] | sigma=[1.50435475 1.02587402] | pi=[0.50631707 0.49368293] | logL=-674.060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Données simulées\n",
    "# -----------------------------\n",
    "np.random.seed(0)\n",
    "\n",
    "N = 300\n",
    "X1 = np.random.normal(loc=-2, scale=1, size=N//2)\n",
    "X2 = np.random.normal(loc=3, scale=1.5, size=N//2)\n",
    "X = np.concatenate([X1, X2])\n",
    "\n",
    "# -----------------------------\n",
    "# Initialisation des paramètres\n",
    "# -----------------------------\n",
    "K = 2  # nombre de clusters\n",
    "\n",
    "mu = np.random.choice(X, K)          # moyennes initiales\n",
    "sigma = np.ones(K)                   # écarts-types initiaux\n",
    "pi = np.ones(K) / K                  # poids initiaux\n",
    "\n",
    "# -----------------------------\n",
    "# Fonction densité gaussienne\n",
    "# -----------------------------\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (1 / (np.sqrt(2*np.pi) * sigma)) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "# -----------------------------\n",
    "# Algorithme EM\n",
    "# -----------------------------\n",
    "max_iter = 100\n",
    "\n",
    "for t in range(max_iter):\n",
    "\n",
    "    # ===== E-step : calcul des responsabilités =====\n",
    "    gamma = np.zeros((N, K))\n",
    "\n",
    "    for k in range(K):\n",
    "        gamma[:, k] = pi[k] * gaussian(X, mu[k], sigma[k])\n",
    "\n",
    "    # normalisation pour que somme_k gamma[n,k] = 1\n",
    "    gamma = gamma / gamma.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # ===== M-step : mise à jour des paramètres =====\n",
    "    Nk = gamma.sum(axis=0)\n",
    "\n",
    "    for k in range(K):\n",
    "        mu[k] = (gamma[:, k] @ X) / Nk[k]\n",
    "        sigma[k] = np.sqrt((gamma[:, k] @ ((X - mu[k])**2)) / Nk[k])\n",
    "        pi[k] = Nk[k] / N\n",
    "\n",
    "    # log-likelihood\n",
    "    likelihood = np.sum(np.log(\n",
    "        sum(pi[k] * gaussian(X, mu[k], sigma[k]) for k in range(K))\n",
    "    ))\n",
    "\n",
    "    print(f\"Iter {t+1:02d} | mu={mu} | sigma={sigma} | pi={pi} | logL={likelihood:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079c551-8738-4515-ab99-72958a0f3fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
