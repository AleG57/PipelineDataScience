{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f82744-27b7-43c0-9c37-70760eb5ccd6",
   "metadata": {},
   "source": [
    "# introduction\n",
    "\n",
    "Cette partie vise à introduire l'élaboration d'une *pipeline* complète de données de la récolte des données brutes au déploiement des modèles statistiques, d'apprentissage automatique et/ou d'apprentissage profond en passant par le traitement des données brutes, la séparation des données nettoyées en, plusieurs sous-datasets pour l'entraînement des modèles et l'élaboration de *dashboards*. Ce guide sur les *pipelines* des séries temporelles se veut exhaustif pour permettre une étude aussi bien légère et rapide, mais aussi plus poussée comportant une compréhension fine de ce qu'est la science des données. Ce guide s'adapte donc aussi bien aux personnes voulant avoir les prérequis de base sur ce qu'est la science des données qu'aux personnes souhaitant approfondir leurs connaissances de base qui recherchent un réel guide / *mémento* de fonctions, modèles, concepts mathématiques permettant de devenir un réel expert en la matière. \n",
    "\n",
    "Ce guide inclut aussi des notions liées à la data science largement déployées en industrie. Bien ce ne soit pas le coeur du métier de *datascientist*, ce dernier se doit d'avoir une bonne compréhension des enjeux qui gravitent autour de son travail.\n",
    "\n",
    "---\n",
    "## 1. Structure d'un projet en *data science*.\n",
    "\n",
    "## 2. Performance management\n",
    "\n",
    "Cette partie est facultative est n'est pas sencée apparaître de base sur ce fichier. Cepedant, au fur et à mesure de mes projets, j'ai trouvé que le temps d'exécution de certains scripts (hors programmation GPU) pouvait prendre un temps considérable lorsque le dataset considéré est de grande taille. C'est pourquoi je rajoute cette partie, bien que facultative pour la pratique de la *data science*, elle peut devenir indispensable pour des *datasets* de grande taille, notament pour le scaling de big data en structure interne.\n",
    "\n",
    "### 2.1 Les bases du multiprocessing\n",
    "\n",
    "Sans rentrer dans les détails d'architecture des ordinateurs, le multiprocessing permet de répartir les calculs à réaliser par le processeur pour réaliser un script. En effet, au lieu de ne prioriser qu'un seul coeur du processeur pour effectuer cette tâche, le multiprocessing permet d'utiliser autant de coeurs que l'on souhaite (dans la limite de notre processeur) pour réaliser la tâche demandée, plus ou moins équitablement en fonction du script. Voici in exemple de multiprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d862d17-8c82-4d4f-b66d-fe533edb08b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def carre(x): # Fonction de pool\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\": # fonction principale\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        resultats = pool.map(carre, [1, 2, 3, 4, 5])\n",
    "    \n",
    "    print(resultats) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e667661-6d86-4f95-be16-c363726162e3",
   "metadata": {},
   "source": [
    "Ce bloc de code permet d'utiliser quatres coeur pour 5 appels de fonction au total (si le processeur en possède au moins 4) pour calculer le carré des éléments de la liste, au lieu de n'utiliser qu'un coeur pour les 5 appels, comme le ferait le script suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f95afc-e4c6-4996-bcaf-1cae17ae44a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[carre(x) for x in [1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abd56e-0564-4537-bb98-b6d231e5ec98",
   "metadata": {},
   "source": [
    "Ce qui permet de réduire grandement la vitesse d'exécution du script. \n",
    "Pour cet exemple, la taille de la liste étant trop petite pour voir la différence, il sera intéressant de voir, par la suite, que sur des échantillons très volumineux ou même des opérations beaucoup plus coûteuses en temps de calcul, on préférera les fonctions de pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e98d2-3f91-4952-9332-94b8f6982de2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Récolte des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c338c-0849-47da-b3dc-f74d1b061e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
