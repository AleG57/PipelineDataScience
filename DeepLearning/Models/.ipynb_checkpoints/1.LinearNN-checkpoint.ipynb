{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e33d6c-185b-4127-bb24-66b2876449b1",
   "metadata": {},
   "source": [
    "# Linear Neural Networks\n",
    "Graphes acycliques orientés (DAG)\n",
    "## 1 Formulation mathématique\n",
    "---\n",
    "### 1.1 Perceptron (Rosenblatt 1958)\n",
    "\n",
    "#### 1.1.1 Architecture\n",
    "\n",
    "Un perceptron est un réseau de neuronnes feedforward avec une seule couche cachée. **C'est un classifieur binaire qui prend en entrée un vecteur $x \\in \\mathbb{R}^n$ et en sortie un scalaire $y \\in \\mathcal{Y} = [-1;1]$**. Soit le dataset $\\mathcal{D} = \\{x_i, y_i\\} \\in \\mathbb{R}^n \\times [-1;1]$, le perceptron est construit à l'aide de l'architecteure SAR (**Sensory, Associative, Response architecture**).\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/Perceptron.png\" alt=\"a\" width=\"500\" height=\"350\">\n",
    "</div>\n",
    "\n",
    "Avec : \n",
    "\n",
    "* $x \\in \\mathbb{R}^n, (x_i)_{i \\in \\mathbb{N}} \\in \\mathbb{R}$ : le vecteur d'entrée\n",
    "* $\\hat{y} = \\hat{r} \\in \\mathbb{R}^K, (\\hat{r}_i)_{i \\in \\mathbb{N}} \\in [-1;1]$ : la valeur de sortie (décision du classifieur)\n",
    "* $\\phi(x) \\in \\mathbb{R}^n$ : features functions avec $\\phi_0(x) = 1$\n",
    "* $\\omega = (\\omega_1, \\dots, \\omega_n) \\in \\mathbb{R}^n$ : le vecteur des poids\n",
    "\n",
    "$$\n",
    "x =  \n",
    "   \\begin{bmatrix}\n",
    "    x_{0}    \\\\\n",
    "    \\vdots   \\\\\n",
    "    x_{n-1}  \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n, \\quad\n",
    "\\phi(x) = \n",
    "    \\begin{bmatrix}\n",
    "    \\phi_0(x)      \\\\\n",
    "    \\vdots         \\\\\n",
    "    \\phi_{n-1}(x)  \\\\\n",
    "   \\end{bmatrix} =\n",
    "    \\begin{bmatrix}\n",
    "    1              \\\\\n",
    "    \\phi_1(x)      \\\\\n",
    "    \\vdots         \\\\\n",
    "    \\phi_{n-1}(x)  \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^{n}, \\quad\n",
    "\\hat{y} = \\hat{r} =  \n",
    "   \\begin{bmatrix}\n",
    "    \\hat{r}_{0} \\\\\n",
    "    \\vdots  \\\\\n",
    "    \\hat{r}_{K-1}  \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^K \\quad\n",
    "\\omega =  \n",
    "   \\begin{bmatrix}\n",
    "    \\omega_{0}    \\\\\n",
    "    \\vdots   \\\\\n",
    "    \\omega_{n-1}  \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n,\n",
    "$$\n",
    "\n",
    "Le classifieur utilise la fonction de décision suivante : \n",
    "\n",
    "$$\n",
    "\\boxed{\\hat{y} = g(w^T\\phi(x))}\n",
    "$$\n",
    "\n",
    "Avec :\n",
    "\n",
    "* $g$ la fonction de décision. La fonction utilisée dépend de la typologie du problème.\n",
    "    - $g(x) = x$ (identité) : régression\n",
    "    - $g(x) = \\text{ReLU}(x) = \\max(0,x)$ (Rectified Linear Unit) : régression\n",
    "    - $g(x) = \\text{sign}(x) = 1 \\quad \\text{si} x >, -1 \\quad \\text{sinon}$ : classification binaire\n",
    "    - $g(x) = \\text{tanh}(x) = \\frac{e^x - e^-z}{e^x + e^-z}$ : classification binaire\n",
    "    - $g(x) = \\text{sigmoid}(x) = \\frac{1}{1+e^-x}$ : classification bianire\n",
    "    - $g(x) = \\text{softmax}(x)$ : classification multiclasse\n",
    "\n",
    "$$\n",
    "x =  \n",
    "   \\begin{bmatrix}\n",
    "    x_{1}    \\\\\n",
    "    \\vdots   \\\\\n",
    "    x_{n}    \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n, \\quad \\text{softmax}(x) = \n",
    "   \\begin{bmatrix}\n",
    "    \\frac{ e^{x_{1}} }{ \\sum_{k=1}^{n} e^{x_{k}} }    \\\\\n",
    "    \\vdots                                           \\\\\n",
    "    \\frac{ e^{x_{n}} }{ \\sum_{k=1}^{n} e^{x_{k}} }    \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "#### 1.1.2 Kernel Perceptron\n",
    "\n",
    "D'une manière générale, on introduit le *kernel* $k$ qui permet de réécrire la fonction de décision du Perceptron :\n",
    "\n",
    "$$\n",
    "\\hat{y} = g(k(w,\\phi(x)))\n",
    "$$\n",
    "\n",
    "qui s'apparente à un SVM.\n",
    "\n",
    "\n",
    "#### 1.1.3 Learning rule\n",
    "\n",
    "Les poids s'actualisent selon la règle suivante :\n",
    "\n",
    "$$\n",
    "\\omega \\longrightarrow\n",
    "\\begin{cases}\n",
    "    \\omega             & \\text{si} \\quad \\hat{y}_i \\quad \\text{est correctement classifié}  \\\\\n",
    "    \\omega + \\phi(x_i) & \\text{si} \\quad \\hat{y}_i \\quad \\text{est faussement classifié} -1 \\\\\n",
    "    \\omega - \\phi(x_i) & \\text{si} \\quad \\hat{y}_i \\quad \\text{est faussement classifié} +1 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Ce qui revient à **la delta rule** :\n",
    "\n",
    "$$\n",
    "\\omega \\longrightarrow \\omega + \\frac{1}{2}(y_i \\hat{y}_i)\\phi(x)\n",
    "$$\n",
    "\n",
    "Interprétation géométrique :\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/DecisionRule.png\" alt=\"a\" width=\"600\" height=\"600\">\n",
    "</div>\n",
    "\n",
    "Pour la delta rule :\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/LearningRule2.png\" alt=\"a\" width=\"600\" height=\"600\">\n",
    "</div>\n",
    "\n",
    "\n",
    "### 1.2 Réseau multicouches\n",
    "\n",
    "On appelle abusivement MLP (Multi Layer Perceptron) un FeedForward Neural Network avec plusieurs couches. PLus le nombre de couches dans le réseaux est grand, plus le réseau sera capable de capter des features et aspets complexes du problèmes. Un réseau avec peu de couches très larges doit apprendre toutes les possibilités pour atteindre le même niveau de performance qu'un réseau \"profond\", i.e. avec un grand nombre de couches cachées. Ilk es tpréférable de construire un réseau profond avec des couches fines. \n",
    "\n",
    "#### 1.2.1 Architecture\n",
    "\n",
    "Le réseau multicouches reprend la même architecture que le Perceptron mais avec plusieurs couches cachées. On rajoute une $n+1$-ième composante à tous les vecteurs d'entrées / sorties d'une compostante égale à 1, représentant le biais (sauf pour la sortie). \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/FFNNmulticouches.png\" alt=\"a\" width=\"600\" height=\"600\">\n",
    "</div>\n",
    "\n",
    "Avec : \n",
    "\n",
    "* $x \\in \\mathbb{R}^{n+1}, (x_i)_{i \\in \\mathbb{N}} \\in \\mathbb{R}$ : le vecteur d'entrée avec $x_n = 1$\n",
    "* $(\\hat{y}^{(l)})_{l \\in [1; L-1]} \\in \\mathbb{R}^K, (\\hat{y}_i^{(l)})_{i, l \\in \\mathbb{N} \\times [1; L-1]} \\in \\mathbb{R}$ : les vecteurs d'entrées / sorties de la couche $l$.\n",
    "* $\\hat{y}^{(L)} \\in \\mathbb{R}^K, (\\hat{y}_i^{(L)})_{i \\in \\mathbb{N}} \\in \\mathbb{R}$ : le vecteur de sortie (dans l'exemple, c'est un classifieur binaire)\n",
    "* $a^{(l)} = \\phi^{(l)}(x) \\in \\mathbb{R}^n$ : features functions avec $a_n^{(l)}(x) = 1 \\quad \\forall l \\in [1; L-1]$\n",
    "* $(w_{i,j}^{(l)})_{i,j,l \\in \\mathbb{N} \\times \\mathbb{N} \\times [1; L-1]} \\in \\mathbb{R}^n$ : les poids de la matrice $W$; $w_{i,j}$ représente le poids du neuronne $i$ de la couche $l-1$ vers le neuronne $j$ de la couche suivante $l$. \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/NeuronsWeight.png\" alt=\"a\" width=\"300\" height=\"300\">\n",
    "</div>\n",
    "\n",
    "$$\n",
    "x =  \n",
    "   \\begin{bmatrix}\n",
    "        x_{0}    \\\\\n",
    "        \\vdots   \\\\\n",
    "        x_{n-1}  \\\\\n",
    "        1        \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n, \\quad\n",
    "a^{(l)} =\n",
    "    \\begin{bmatrix}\n",
    "        a_1^{(l)}(x)     \\\\\n",
    "        \\vdots            \\\\\n",
    "        a_{n-1}^{(l)}(x)  \\\\\n",
    "        1                 \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^{n}, \\quad\n",
    "\\hat{y}^{(l)} =  \n",
    "   \\begin{bmatrix}\n",
    "        \\hat{y}_{0}^{(l)} \\\\\n",
    "        \\vdots  \\\\\n",
    "        \\hat{y}_{K-1}^{(l)}  \\\\\n",
    "        1 \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^{K+1} \\quad \\forall l \\in [1;L-1] \\quad\n",
    "\\hat{y}^{(L)} =  \n",
    "   \\begin{bmatrix}\n",
    "        \\hat{y}_{0}^{(L)} \\\\\n",
    "        \\vdots  \\\\\n",
    "        \\hat{y}_{K-1}^{(L)}  \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^K \\quad\n",
    "W = \n",
    "   \\begin{bmatrix}\n",
    "    w_{1,1} & \\dots & w_{1,L} \\\\\n",
    "    \\vdots & x_{i,n} & \\vdots \\\\\n",
    "    w_{n,1} & \\dots & w_{n,L} \\\\\n",
    "   \\end{bmatrix} \\in \\mathcal{M}_{n,L}(\\mathbb{R})\n",
    "$$\n",
    "\n",
    "Pour chaques éléments de chaque couches cachées $l$, on a les relations E/S suivantes :\n",
    "\n",
    "$$\n",
    "y_{i}^{(l)} = g(\\sum_{j}\\omega_{i,j}^{(l)}y_i^{(l-1)})\n",
    "$$\n",
    "\n",
    "vectoriellement, on a :\n",
    "\n",
    "$$\n",
    "y^{(l)} = g((\\omega^{(l)})^{T}y^{(l-1)}) \\quad \\forall l \\in [1,L]\n",
    "$$\n",
    "\n",
    "En considérant $y^{(0)} = x$ et $y^{(L)} = f((\\omega^{(L)})^{T}y^{(L-1)})$, $f$ pas nécéssairement égal à $g \\quad \\forall x$  et donc, pour la dernière couche :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y^{(L)} &= f( (\\omega^{(L)})^T y^{(L-1)} )                                                 \\\\\n",
    "        &= f( (\\omega^{(L)})^T g((\\omega^{(L-1)})^T y^{(L-2)}) )                           \\\\\n",
    "        &= f( (\\omega^{(L)})^T g((\\omega^{(L-1)})^T g( (\\omega^{(L-2)})^T y^{(L-3)}) ) )   \\\\\n",
    "        &= \\vdots                                                                          \\\\\n",
    "        &= f((\\omega^{(L)})^T g((\\omega^{(L-1)})^T) g(\\dots g((\\omega^{(1)})^T y^{(0)})))  \\\\\n",
    "y^{(L)} &= f((\\omega^{(L)})^T g((\\omega^{(L-1)})^T) g(\\dots g((\\omega^{(1)})^T x)))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* $f, g$ les fonctions de décision pour le vecteur de sortie et d'activation pour les vecteurs qui représentent les couches cachées respectivement. $f$ et $g$ peuvent êtres de même nature même si on déconseille cette pratique. La fonction utilisée dépend de la typologie du problème.\n",
    "    - $g(x) = x$ (identité) : régression\n",
    "    - $g(x) = \\text{ReLU}(x) = \\max(0,x)$ (Rectified Linear Unit) : régression\n",
    "    - $g(x) = \\text{LeakyReLU}(x) = \\max(x, \\alpha x), \\quad \\alpha \\in [0;1]$ : variante de ReLU, régression\n",
    "    - $g(x) = \\text{GELU}(x)$ : : variante de ReLU, régression\n",
    "    - $g(x) = \\text{sign}(x) = 1 \\quad \\text{si} x > 0,\\quad -1 \\quad \\text{sinon}$ : classification binaire\n",
    "    - $g(x) = \\text{tanh}(x) = \\frac{e^x - e^-z}{e^x + e^-z}$ : classification binaire\n",
    "    - $g(x) = \\text{sigmoid}(x) = \\frac{1}{1+e^-x}$ : classification bianire\n",
    "    - $g(x) = \\text{softmax}(x)$ : classification multiclasse\n",
    "\n",
    "$$\n",
    "x =  \n",
    "   \\begin{bmatrix}\n",
    "    x_{1}    \\\\\n",
    "    \\vdots   \\\\\n",
    "    x_{n}    \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n, \\quad \\text{softmax}(x) = \n",
    "   \\begin{bmatrix}\n",
    "    \\frac{ e^{x_{1}} }{ \\sum_{k=1}^{n} e^{x_{k}} }    \\\\\n",
    "    \\vdots                                            \\\\\n",
    "    \\frac{ e^{x_{n}} }{ \\sum_{k=1}^{n} e^{x_{k}} }    \\\\\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^n\n",
    "$$\n",
    "#### 1.2.2 Un problème d'optimisation\n",
    "\n",
    "En fonction du type de problème (régression ou classification), la fonction de perte ne sera pas la même. En effet :\n",
    "\n",
    "**Régression**\n",
    "* $MSE$ / $RMSE$\n",
    "* $L_2$ *loss*\n",
    "\n",
    "**Classification binaire / régression logistique**\n",
    "* *likelyhood*\n",
    "* *log loss*\n",
    "* *cross entropy* (*negative log-likelyhood*) [régression logistique] avec $\\text{sigmoid}$\n",
    "\n",
    "**Classification multiclasse**\n",
    "* *cross entropy* (*negative log-likelyhood*) avec $\\text{softmax}$\n",
    "\n",
    "On note $\\mathcal{L}$ la fonction de perte :\n",
    "\n",
    "* $$\n",
    "\\mathcal{L}_{L_{2}}(y, \\hat{y}) = \\frac{1}{N}\\sum_{i=0}^{N}||y_i - \\hat{y_i}||_{2}^{2}\n",
    "$$\n",
    "\n",
    "* $$\n",
    "\\mathcal{L}_{MSE}(y, \\hat{y}) = \\frac{1}{N}\\sum_{i=0}^{N}(y_i - \\hat{y_i})²\n",
    "$$\n",
    "\n",
    "* $$\n",
    "\\mathcal{L}_{likelyhood}(y, \\hat{y}) = \\prod_{i=0}^{n} P(y=y_i|x_i) = \\prod_{i=0}^{n} p(x_i| \\omega)^{y_{i}}(1 - p(x_i|\\omega))^{1-y_i}\n",
    "$$\n",
    "\n",
    "\n",
    "* $$\n",
    "\\mathcal{L}_{cross-entropy}(y, \\hat{y}) = -y\\log(\\hat{y}) - (1 - y)\\log{(1 - \\hat{y})}\n",
    "$$\n",
    "\n",
    "Dans tous les cas, on cherche à minimiser la fonction de perte pour trouvers les coefficients de la matrice des poids $W$ tel que :\n",
    "\n",
    "$$\n",
    "W = \\text{arg}\\min_{\\omega_{i,j}} \\mathcal{L}(y, \\hat{y})\n",
    "$$\n",
    "\n",
    "Pour le cas de la régression, une solution analytique est trouvée en dérivant le Lagrangien du problème. Comme le problème d'optimisation n'a pas de contraintes, le Lagrangien et égal à la fonction de perte à minimiser et il n'y a pas de K.K.T..\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\omega}(\\omega) = 0_{\\mathbb{R}^n} \\Longleftrightarrow \\omega = X^TX \n",
    "$$ \n",
    "\n",
    "Ce qui force à réaliser cette opération sur le dataset tout entier. En raison de la qunatité de données nécéssaire pour entraîner un réseau de neuronnes, cette opération n'est pas réalisable avec la puissance des ordinateurs actuels. On se contente donc d'une solution approchées à l'aide de la descente de gradient.\n",
    "\n",
    "#### 1.2.3 Descente de gradient\n",
    "\n",
    "Comme évoqué précédement, peut importe le problème, il faut minimiser la fonction de perte $\\mathcal{L}$ tel que :\n",
    "\n",
    "$$\n",
    "\\min_{\\omega} \\mathcal{L}(\\omega, x, y) = \\min_{\\omega_i} \\sum_{i} \\mathcal{L}(\\omega, x_i, y_i)\n",
    "$$\n",
    "\n",
    "\n",
    "Il existe plusieurs méthodes de descentes de gradient :\n",
    "\n",
    "- **Batch**\n",
    "\n",
    "La descente de gradient par batch réalise une descente de gradient sur tout le dataset. Le vecteur de poids $\\omega$ s'actualise selon la règle suivante :\n",
    "\n",
    "$$\n",
    "\\omega_{t+1} = \\omega_t - \\epsilon_t \\nabla_{\\omega}\\mathcal{L}(\\omega, x, y)\n",
    "$$\n",
    "\n",
    "Avec $\\epsilon_t$ le pas d'apprentissage (**learning rate**).\n",
    "\n",
    "- **Minibatch**\n",
    "\n",
    "La descente de gradient par mini batch réalise une descente de gradient sur chaque parties de taille égale avec échantillons randomizés du dataset. C'est un estimateur bruité de la solution. Généralement, la taille du batch est un bloc de 64 échantillons, 128 ou une puissance de 2 supérieure tel que $|\\mathcal{J}| = M = 64,128...$. Pour tous les minibatches, on calcule les poids :\n",
    "\n",
    "$$\n",
    "\\omega_{t+1} = \\omega_t - \\epsilon_t \\frac{1}{M} \\sum_{j \\in \\mathcal{J}} \\nabla_{\\omega}\\mathcal{L}(\\omega, x_i, y_i)\n",
    "$$\n",
    "\n",
    "Cette méthode est plus rapide que la descente de gradient par batch et facilement parallélisable. Attention cependant à ne pas prendre des tailles de minibatch trop petite ou trop grande. Si M = 1, le calcul ne sera pas parallèlisable. Si $M=N$ (taille du dataset), le minimum local trouvé ne sera pas le plus optimal.\n",
    "\n",
    "- **Stochastique (SGD)**\n",
    "\n",
    "La descente de gradient stochastique, SGD est un estimateur bruité de la solution du problème d'optimisation.\n",
    "\n",
    "$$\n",
    "\\omega_{t+1} = \\omega_t - \\epsilon_t \\sum_{j \\in \\mathcal{J}} \\nabla_{\\omega}\\mathcal{L}(\\omega, x_i, y_i)\n",
    "$$\n",
    "\n",
    "Avec $\\epsilon_t$ le pas d'apprentissage (**learning rate**). Cette méthode est plus rapide que la descente de gradient par batch.\n",
    "\n",
    "- **Backpropagation**\n",
    "\n",
    "- **Momentum**\n",
    "\n",
    "Pour les fonctions de perte fortement non convexe, on ajoute la notion de *momentum*. Le *momentum* représente l'inertie en physique. C'est ici lié à la vitesse à laquelle se déplace le gradient. On rajoute alors le terme de vitesse de propagation du gradient à l'itération $t$, $v_t$ toujours en gardant le learning rate $\\epsilon_t$.\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{eqnarray}\n",
    "v_{t+1} = \\mu v_t - \\epsilon_t \\nabla_{\\omega} \\mathcal{L}(\\omega, x, y) \\\\\n",
    "\\omega_{t+1} = \\omega_{t} + v_{t+1} \\\\\n",
    "\\end{eqnarray}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Avec $\\mu \\approx 0.99$\n",
    "\n",
    "Le **momentum de Nesterov** rajoute la notion de direction dans laquelle le gradient va aller dans la prochaine itération.\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{eqnarray}\n",
    "\\bar{\\omega}_t = \\omega_t + \\mu v_t \\\\\n",
    "v_{t+1} = \\mu v_t - \\epsilon_t \\nabla_{\\omega} \\mathcal{L}(\\bar{\\omega}, x, y) \\\\\n",
    "\\omega_{t+1} = \\omega_{t} + v_{t+1} \\\\\n",
    "\\end{eqnarray}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Voici un exemple des différentes méthodes de calcul de la descente de gradient en fonction du learning rate $\\epsilon_t$ pour une perte $\\mathcal{L}(w) = (\\omega - 2)^2$\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"src/pics/FFNN/gradient_descent_grid.gif\" alt=\"a\" width=\"1200\" height=\"900\">\n",
    "</div>\n",
    "\n",
    "#### 1.2.4 Calcul du gradient\n",
    "\n",
    "Le calcul de la quantité $\\nabla_{\\omega}\\mathcal{L}$ réclame le calcul de :\n",
    "\n",
    "$$\n",
    "\\text{pour} \\quad \\mathcal{L}(\\omega,x,y) \\in \\mathbb{R}, \\omega \\in \\mathbb{R}^n, \\quad \\nabla_{\\omega}\\mathcal{L}(\\omega, x, y) =\n",
    "\\frac{\\partial \\mathcal{L}(\\omega, x, y)}{\\partial \\omega} = \n",
    "[ \\frac{\\partial \\mathcal{L}(\\omega, x, y)}{\\partial \\omega_1}, \\dots, \\frac{\\partial \\mathcal{L}(\\omega, x, y)}{\\partial \\omega_n} ] \\in \\mathcal{M}_{1,n}(\\mathbb{R})\n",
    "$$\n",
    "\n",
    "Qui provient de la jacobienne de $\\mathcal{L}$. Par exemple, si on avait :\n",
    "\n",
    "$$\n",
    "\\text{pour} \\quad \\mathcal{L}(\\omega,x,y) \\in \\mathbb{R}^p, \\omega \\in \\mathbb{R}^n, \\quad \\nabla_{\\omega}\\mathcal{L}(\\omega, x, y) =\n",
    "\\frac{\\partial \\mathcal{L}(\\omega, x, y)}{\\partial \\omega} = \n",
    "   \\begin{bmatrix}\n",
    "    \\frac{\\partial \\mathcal{L}_1(\\omega, x, y)}{\\partial \\omega_1} & \\dots & \\frac{\\partial \\mathcal{L}_1(\\omega, x, y)}{\\partial \\omega_n} \\\\\n",
    "    \\vdots & \\frac{\\partial \\mathcal{L}_i(\\omega, x, y)}{\\partial \\omega_j} & \\vdots \\\\\n",
    "    \\frac{\\partial \\mathcal{L}_p(\\omega, x, y)}{\\partial \\omega_1} & \\dots & \\frac{\\partial \\mathcal{L}_p(\\omega, x, y)}{\\partial \\omega_n} \\\\\n",
    "   \\end{bmatrix}\n",
    "\\in \\mathcal{M}_{p,n}(\\mathbb{R})\n",
    "$$\n",
    "\n",
    "Inverser la jacobienne sur des réseaux très profonds requiert une grosse puissance de calcul. On utilise alors une décomposition des dérivées en fonctions plus simples à l'aide de graphes de calcul. Ce chaînage a néanmoins plusieurs possibilités : pour un réseau de $L$ couches de $N$ unités, on a $N^L$ possibilités. On utilise alors  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348c35a-1d31-4a9a-925b-68dfb1ea4430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
